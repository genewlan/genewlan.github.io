<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>GANs网络在二维平面的实现 | GeneWlan</title><meta name="author" content="ZhangLei"><meta name="copyright" content="ZhangLei"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[TOC] GUNs的发迹史——刨根问底儿 上一篇中，我们使用量GNN网络进行了辛烷溶解度的预测。那么问题来了，假如我们只有这些化合物是远远不能支撑人们日益增长的美好生活需要所需要的物质基础的。而现实生活中往往也是如此，化学家们经过几百年的努力分离出来许多化合物，但其中大部分不是“歪瓜”就是“裂枣”（可不敢胡说，或许是宝儿），不是产量少就是用不了，只有少量成功的化合物也被西方某大国成功的垄断。更重">
<meta property="og:type" content="article">
<meta property="og:title" content="GANs网络在二维平面的实现">
<meta property="og:url" content="http://genewlan.github.io/2023/04/14/GAN2D/index.html">
<meta property="og:site_name" content="GeneWlan">
<meta property="og:description" content="[TOC] GUNs的发迹史——刨根问底儿 上一篇中，我们使用量GNN网络进行了辛烷溶解度的预测。那么问题来了，假如我们只有这些化合物是远远不能支撑人们日益增长的美好生活需要所需要的物质基础的。而现实生活中往往也是如此，化学家们经过几百年的努力分离出来许多化合物，但其中大部分不是“歪瓜”就是“裂枣”（可不敢胡说，或许是宝儿），不是产量少就是用不了，只有少量成功的化合物也被西方某大国成功的垄断。更重">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-04-14T06:57:17.710Z">
<meta property="article:modified_time" content="2023-08-31T07:43:08.335Z">
<meta property="article:author" content="ZhangLei">
<meta property="article:tag" content="GANS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://genewlan.github.io/2023/04/14/GAN2D/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'GANs网络在二维平面的实现',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-31 15:43:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start -->
    <style>
      #background-effect {
        position: fixed !important;
        top: 0px;
        left: 0px;
        z-index: -1;
        width: 100%;
        height: 100%
      }
    </style>
  <!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="GeneWlan" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/03/21/ZVUmQFknE2JosXT.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="GeneWlan"><span class="site-name">GeneWlan</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">GANs网络在二维平面的实现</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-04-14T06:57:17.710Z" title="发表于 2023-04-14 14:57:17">2023-04-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-31T07:43:08.335Z" title="更新于 2023-08-31 15:43:08">2023-08-31</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="GANs网络在二维平面的实现"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[TOC]</p>
<h1>GUNs的发迹史——刨根问底儿</h1>
<p>上一篇中，我们使用量GNN网络进行了辛烷溶解度的预测。那么问题来了，假如我们只有这些化合物是远远不能支撑人们日益增长的美好生活需要所需要的物质基础的。而现实生活中往往也是如此，化学家们经过几百年的努力分离出来许多化合物，但其中大部分不是“歪瓜”就是“裂枣”（可不敢胡说，或许是宝儿），不是产量少就是用不了，只有少量成功的化合物也被西方某大国成功的垄断。更重要的是，现实世界我们接触到的东西都是以平面或更高维的形式展现，一维是远远满足不了那里的人们追求欲望（~不，愿望），实现地强大且持久得野心的（~不，决心的）。</p>
<p>那么，有没有一种可以让我们快速生成大量非歪瓜劣枣的化合物呢？嗯，maybe生成网络就是答案之一。下面是博士卖驴的过程：</p>
<p>我们知道，机器学习在历史上也经历了三起三落，不断被打入冷宫，又被提拔为皇后。上世纪80年代，机器学习再度兴起，神经网络开始流行了。当时，人们主要的训练方式是监督学习，就是通过输入数据和对应的标签，让神经网络不断地调整自身的参数，以最小化预测值与真实标签之间的差距，从而实现模型的训练和优化，这就是我们熟知的反向传播算法。</p>
<p>这种算法的优点和缺点都很明显。优势是，它是可以处理大规模的数据集和复杂的非线性关系，而且算法效率较高，容易实现。但是，它经常如容易陷入局部最优解、对初始权重和偏置比较敏感、需要大量的标注数据等。尤其是在解决多层神经网络的过程中，劣势更加明显，训练过程更加困难。为了解决这个问题，研究人员开始尝试使用无监督学习的方法来训练神经网络。</p>
<p>值得一提的是当时最具影响的网络是自组织特征映射（Self-Organizing Feature Map，SOFM），也称为Kohonen网络。它旨在实现大规模数据的降维和可视化。主要思想是通过在输入空间中构建一个拓扑结构，将高维数据映射到低维空间中，并保持数据之间的拓扑关系，因此在图像压缩和信号处理等线性问题上面很有市场。Kohonen网络主要通过线性变换和欧氏距离量度来完成对目标的高效压缩，因此无法有效处理非线性数据和复杂分布的数据。于是需求造就市场，玻尔兹曼机（Boltzmann Machine）诞生了。</p>
<p>玻尔兹曼机是一种基于能量模型的概率生成模型，可以用于实现图像、音乐等多种生成任务。玻尔兹曼机最早是由物理学家Hinton等人提出的，它的原理是基于物理学中的玻尔兹曼分布理论，将神经元之间的相互作用看作是带有能量的粒子之间的相互作用，从而建立了一个能量模型。以下是玻尔兹曼机的工作过程：</p>
<ol>
<li>数据表示：将输入数据转换为向量形式，并将其作为可见层的状态。</li>
<li>随机初始化：将网络的权重和偏置随机初始化，以便在训练过程中进行优化。</li>
<li>Gibbs采样：通过交替执行正向传播和反向传播来更新网络的状态。在正向传播中，将可见层的状态传递到隐藏层，然后通过隐含层的状态重新计算可见层的状态。在反向传播中，将可见层的状态作为输出，然后通过反向传播误差来更新网络的权重和偏置。</li>
<li>训练：通过多次执行Gibbs采样来训练网络，直到网络收敛。在训练过程中，网络会不断地调整权重和偏置，以最小化能量函数。</li>
<li>生成：通过从网络中的随机状态开始，执行多次Gibbs采样来生成新的数据。在生成过程中，网络会根据其学习到的数据分布生成具有相似特征的新数据。</li>
</ol>
<p>重点来了：第五步。生成。主要目的是生成新的样本，以测试和验证模型的性能和效果。在波尔兹曼机中，生成是指从随机初始化的状态开始，通过不断迭代计算，生成新的样本。生成的过程类似于模拟退火，通过概率分布来探索样本空间，并从中采样生成新的样本。生成的样本可以用于评估模型的还原能力、泛化能力以及样本生成能力，从而判断模型的性能和效果。</p>
<p>然而，玻尔兹曼机的训练过程非常困难，因为需要对所有可能的状态进行计算，这个计算复杂度爆炸式增长，介于当时的电脑拥有强悍的11公斤身躯，超大的256k缓存，720k极致超大内存，以及超低的2280$的售价。玻尔兹曼机毫无疑问的流产了。就像妃子失宠之后很难再被想起一样，很长一段时间内没有得到广泛的应用。</p>
<p>后来~~~</p>
<p>后来，原始玻尔兹曼机的无向图改成了有向图，受限玻尔兹曼机（Restricted Boltzmann Machine ，RBM)诞生了；贪心算法接入，RBM变成了深度信念网络（Deep Belief Networks, DBN）。后来，专家系统被重新捡起来，人们想加入一些已知的确定的进入网络，将输入压缩成低维编码，并对解码器的误差进行重构，于是玻尔兹曼机又发展成了自编码器（Autoencoder, AE）。但是这货眼镜只能看到手里有的东西，对未知的东西则看缘分，这造成过了局部拟合，生成的东西乱七八遭，人们对AE的潜在数据空间进行约束，发展到了VAE。VAE在生成数据方面表现出色，但在生成高分辨率和多样化的数据方面仍然存在一些限制。于是一个生成器网络和一个判别器网络加入，判别器网络可以更好地区分真实数据和生成数据的生成器诞生了—gans，这是一款大规模流行生成对抗网络。</p>
<p>其数学基本思想发展如下：</p>
<img src="/2023/04/14/GAN2D/Snipaste_2023-04-12_14-31-48.png" style="zoom:80%;">
<p>当然后来还发展出了AGANs、BGANs、CGANs、、、WGANs，基本26个字母都用完了。无奈的人只有加单词如：StyleGANs，Progressive GANs、Self-Attention GANs、BigGANs、StarGANs等等，非常热闹。如下图：</p>
<img src="/2023/04/14/GAN2D/Evolution-of-GAN-model-year-wise.png">
<p>总之，这货还在疯狂的繁衍后代。</p>
<hr>
<h1>GUNs有啥用</h1>
<p>下面简单介绍一下，GAN（Generative Adversarial Networks）是一种深度学习模型，旨在生成与训练数据相似的新数据，由两个神经网络组成：生成器和判别器。GAN是通过对抗性训练的方式，让生成器不断生成与训练数据相似的新数据，同时让判别器不断判断生成的数据是否真实。这个过程类似于博弈论中的零和游戏，两个网络相互对抗，从而提高生成器的生成能力。</p>
<p>GAN的应用，包括图像生成、视频生成、语音合成等。我会讲解GAN在这些领域中的应用原理和方法，并展示一些实际应用的例子，让研究生了解GAN在实际应用中的价值和意义。</p>
<p>GAN算法的实现：包括生成器网络、判别器网络、损失函数、梯度下降算法等。一句话总结：生成器网络接收随机向量作为输入，并通过一系列的转换和变换生成与训练数据相似的新数据；判别器网络接收训练数据和生成器生成的数据作为输入，并输出一个概率值，表示输入的数据是真实数据的概率；损失函数，使得生成器和判别器能够相互对抗，同时被不断优化；梯度下降算法计算网络的参数梯度，并进行参数更新，略长~~。</p>
<p>总之：GANs是由两个神经网络组成的模型，一个是生成器网络，另一个是判别器网络，它们通过博弈的方式一起训练，使得生成器可以生成逼真的数据样本。GANs的工作流程如下：</p>
<ol>
<li>
<p>定义生成器和判别器网络。生成器网络将潜在的随机噪声输入转化为逼真的数据样本。判别器网络则判断输入的数据是真实的样本还是由生成器生成的假样本。</p>
</li>
<li>
<p>训练判别器网络。给定一批真实的数据样本和由生成器生成的假样本，判别器网络将对它们进行分类并计算损失函数。损失函数衡量了判别器网络对真实和假样本分类的准确性。</p>
</li>
<li>
<p>训练生成器网络。给定一批潜在的随机噪声输入，生成器网络将生成一批假样本。生成器的目标是欺骗判别器，使得它无法区分生成的假样本和真实的样本。因此，生成器的损失函数要最小化判别器将生成的假样本分类为假样本的概率。</p>
</li>
<li>
<p>交替训练生成器和判别器网络。在每一轮迭代中，生成器网络和判别器网络都要更新它们的参数，以最小化它们的损失函数。这个训练过程会一直进行，直到生成器能够生成逼真的数据样本，判别器无法准确地区分真实和假样本。</p>
</li>
<li>
<p>使用生成器生成新的数据样本。一旦生成器训练好了，就可以使用它生成新的逼真的数据样本，这些样本可以被用于各种应用，如图像修复、图像生成等。</p>
</li>
</ol>
<p>是不是很懵，没关系：</p>
<p>假设你有一个假币制造机，你希望这个机器可以制造跟真币一样逼真的假币，但是你不知道怎样制造才能达到这个目标。那么你可以使用GANs来解决这个问题。</p>
<p>首先，你需要有一些真币样本，这些真币样本将作为GANs的训练数据。你需要训练两个神经网络，一个是生成器网络，另一个是判别器网络。</p>
<p>生成器网络会生成假的币样本，判别器网络会判断这些样本是真币还是假币。在训练过程中，生成器网络不断生成更加逼真的假币样本，而判别器网络则不断提高对真币和假币的区分能力。</p>
<p>经过多次的迭代训练，你的生成器网络最终可以生成非常逼真的假币样本，而判别器网络也可以很难区分真币和假币。这样，你就成功地制造了逼真的假币，而GANs技术为你提供了一种有效的解决方案。</p>
<p>看图说话：</p>
<img src="/2023/04/14/GAN2D/Snipaste_2023-04-12_14-55-59.png" style="zoom:80%;">
<p>最终目的：让超级监视器认为真钱和假钱没差别，就像这样：</p>
<p>​           <img src="/2023/04/14/GAN2D/Snipaste_2023-04-12_15-05-31.png" style="zoom: 80%;"></p>
<p>于是：废纸变黄金</p>
<p><strong>好的有了这些知识，你就可以吊打南村群童了。但是，想踢馆初中生你还需要知道怎么操作</strong></p>
<p>下面实现一个对抗生成网络（GAN）的完整实例，包括数据处理、模型构建、训练和预测，使用 Tensorflow 和 Python 编程。我们将使用一个官方的手写数字数据集来训练一个 GAN，生成新的手写数字图像。这将next—-新化合物生成的基础。</p>
<h1>GUN的实现</h1>
<hr>
<h2 id="用keras搭一个神经网络的失败案例">用keras搭一个神经网络的失败案例</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Input, Dense, Reshape, Flatten, Dropout, Conv2D, Conv2DTranspose</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> BatchNormalization, Activation, LeakyReLU</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential, Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">(X_train, _), (_, _) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">X_train = X_train / <span class="number">127.5</span> - <span class="number">1.</span></span><br><span class="line">X_train = np.expand_dims(X_train, axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型参数</span></span><br><span class="line">img_rows = <span class="number">28</span></span><br><span class="line">img_cols = <span class="number">28</span></span><br><span class="line">channels = <span class="number">1</span></span><br><span class="line">img_shape = (img_rows, img_cols, channels)</span><br><span class="line">z_dim = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义生成器模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_generator</span>(<span class="params">img_shape, z_dim</span>):</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Dense(<span class="number">256</span>, input_dim=z_dim))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(<span class="number">512</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1024</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(np.prod(img_shape), activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.add(Reshape(img_shape))</span><br><span class="line"></span><br><span class="line">    z = Input(shape=(z_dim,))</span><br><span class="line">    img = model(z)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Model(z, img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义判别器模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_discriminator</span>(<span class="params">img_shape</span>):</span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(Flatten(input_shape=img_shape))</span><br><span class="line">    model.add(Dense(<span class="number">512</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>)) </span><br><span class="line">    model.add(Dense(<span class="number">256</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>)) </span><br><span class="line">    model.add(Dense(<span class="number">128</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    img = Input(shape=img_shape)</span><br><span class="line">    validity = model(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Model(img, validity)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建 GAN 模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_gan</span>(<span class="params">generator, discriminator</span>):</span><br><span class="line">    discriminator.trainable = <span class="literal">False</span></span><br><span class="line">    z = Input(shape=(z_dim,))</span><br><span class="line">    img = generator(z)</span><br><span class="line">    validity = discriminator(img)</span><br><span class="line">    <span class="keyword">return</span> Model(z, validity)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">generator = build_generator(img_shape, z_dim)</span><br><span class="line">discriminator = build_discriminator(img_shape)</span><br><span class="line">gan = build_gan(generator, discriminator)</span><br><span class="line">optimizer = Adam(<span class="number">0.0002</span>, <span class="number">0.5</span>)</span><br><span class="line">discriminator.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=optimizer, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">gan.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=optimizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">epochs = <span class="number">10000</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">sample_interval = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="comment"># 训练判别器</span></span><br><span class="line">    idx = np.random.randint(<span class="number">0</span>, X_train.shape[<span class="number">0</span>], batch_size)</span><br><span class="line">    imgs = X_train[idx]</span><br><span class="line">    noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, z_dim))</span><br><span class="line">    gen_imgs = generator.predict(noise)</span><br><span class="line">    d_loss_real = discriminator.train_on_batch(imgs, np.ones((batch_size, <span class="number">1</span>)))</span><br><span class="line">    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((batch_size, <span class="number">1</span>)))</span><br><span class="line">    d_loss = <span class="number">0.5</span> * np.add(d_loss_real, d_loss_fake)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练生成器</span></span><br><span class="line">    noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, z_dim))</span><br><span class="line">    g_loss = gan.train_on_batch(noise, np.ones((batch_size, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印损失</span></span><br><span class="line">    <span class="keyword">if</span> epoch % sample_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>, Discriminator Loss: <span class="subst">&#123;d_loss[<span class="number">0</span>]&#125;</span>, Generator Loss: <span class="subst">&#123;g_loss[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机生成新图像</span></span><br><span class="line">        r, c = <span class="number">5</span>, <span class="number">5</span></span><br><span class="line">        noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (r * c, z_dim))</span><br><span class="line">        gen_imgs = generator.predict(noise)</span><br><span class="line">        gen_imgs = <span class="number">0.5</span> * gen_imgs + <span class="number">0.5</span></span><br><span class="line">        fig, axs = plt.subplots(r, c)</span><br><span class="line">        cnt = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(r):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(c):</span><br><span class="line">                axs[i,j].imshow(gen_imgs[cnt, :,:,<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">                axs[i,j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">                cnt += <span class="number">1</span></span><br><span class="line">        plt.show()  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最后输出是这样婶儿的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>/<span class="number">1</span> [==============================] - 0s 50ms/step</span><br><span class="line">Epoch <span class="number">0</span>, Discriminator Loss: <span class="number">0.0917658281326294</span>, Generator Loss: <span class="number">0.00045222198241</span></span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;</span><br><span class="line">Epoch <span class="number">1000</span>, Discriminator Loss: <span class="number">8.101632460951805</span>, Generator Loss: <span class="number">0.00000649235166</span></span><br></pre></td></tr></table></figure>
<img src="/2023/04/14/GAN2D/Snipaste_2023-04-12_16-56-38.png" title="style=&quot;zoom:150%;&quot;">
<p>打眼一看，这出问题了啊。</p>
<p>D_loss不断升高，幅度不大，G_loss不断下降，几何级下降，图像一片雪花。—&gt;鉴别器太弱了,把尿片当成宝了，什么垃圾都给你留下。</p>
<p><strong>堆叠层数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 定义生成器模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_generator</span>(<span class="params">img_shape, z_dim</span>):</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Dense(<span class="number">128</span>, input_dim=z_dim))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(<span class="number">256</span>, input_dim=z_dim))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(<span class="number">512</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1024</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(BatchNormalization(momentum=<span class="number">0.8</span>))</span><br><span class="line">    model.add(Dense(np.prod(img_shape), activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.add(Reshape(img_shape))</span><br><span class="line">    z = Input(shape=(z_dim,))</span><br><span class="line">    img = model(z)</span><br><span class="line">    <span class="keyword">return</span> Model(z, img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义判别器模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_discriminator</span>(<span class="params">img_shape</span>):</span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(Flatten(input_shape=img_shape))</span><br><span class="line">    model.add(Dense(<span class="number">512</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">256</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">128</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">64</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">32</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.2</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">    img = Input(shape=img_shape)</span><br><span class="line">    validity = model(img)</span><br><span class="line">    <span class="keyword">return</span> Model(img, validity)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>看看效果（Epoch 5000），顺便调个参数吧：optimizer = Adam(0.0001, 0.9)</p>
<p><img src="/2023/04/14/GAN2D/Snipaste_2023-04-12_22-36-51.png" alt></p>
<p>这~，这是嘛呀！！！！还是不行，手搓航母吧！</p>
<p>有谁调试成立一定@我</p>
<hr>
<h2 id="换pytorch数据库">换pytorch数据库</h2>
<h3 id="非卷积对抗神经网络">非卷积对抗神经网络</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">image_size = [<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>]</span><br><span class="line">latent_dim = <span class="number">96</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"><span class="comment">##生成器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(latent_dim, <span class="number">128</span>),</span><br><span class="line">            torch.nn.BatchNorm1d(<span class="number">128</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">256</span>),</span><br><span class="line">            torch.nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            torch.nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            torch.nn.BatchNorm1d(<span class="number">1024</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, np.prod(image_size, dtype=np.int32)),</span><br><span class="line">            nn.Sigmoid())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>):</span><br><span class="line">        output = self.model(z)</span><br><span class="line">        image = output.reshape(z.shape[<span class="number">0</span>], *image_size)</span><br><span class="line">        <span class="keyword">return</span> image</span><br><span class="line"><span class="comment">##监视器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Linear(np.prod(image_size, dtype=np.int32), <span class="number">512</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            torch.nn.GELU(),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">128</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">64</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">32</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">32</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image</span>):</span><br><span class="line">        prob = self.model(image.reshape(image.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> prob</span><br><span class="line"><span class="comment">##数据库</span></span><br><span class="line">dataset = torchvision.datasets.MNIST(<span class="string">&quot;mnist_data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,transform=torchvision.transforms.Compose([torchvision.transforms.Resize(<span class="number">28</span>),torchvision.transforms.ToTensor(),]))</span><br><span class="line"></span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##起个名，让他们准备干活</span></span><br><span class="line">generator = Generator()</span><br><span class="line">discriminator = Discriminator()</span><br><span class="line"><span class="comment">##更新损失函数</span></span><br><span class="line">g_optimizer = torch.optim.Adam(generator.parameters(), lr=<span class="number">0.0003</span>, betas=(<span class="number">0.4</span>, <span class="number">0.8</span>), weight_decay=<span class="number">0.0001</span>)</span><br><span class="line">d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=<span class="number">0.0003</span>, betas=(<span class="number">0.4</span>, <span class="number">0.8</span>), weight_decay=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"></span><br><span class="line">labels_one = torch.ones(batch_size, <span class="number">1</span>)</span><br><span class="line">labels_zero = torch.zeros(batch_size, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#循环起来</span></span><br><span class="line">num_epoch = <span class="number">20</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="keyword">for</span> i, mini_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        gt_images, _ = mini_batch  </span><br><span class="line">        z = torch.randn(batch_size, latent_dim)</span><br><span class="line">        pred_images = generator(z)</span><br><span class="line"></span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line">        recons_loss = torch.<span class="built_in">abs</span>(pred_images-gt_images).mean()</span><br><span class="line">        g_loss = recons_loss*<span class="number">0.05</span> + loss_fn(discriminator(pred_images), labels_one)</span><br><span class="line">        g_loss.backward()</span><br><span class="line"></span><br><span class="line">        g_optimizer.step()</span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        real_loss = loss_fn(discriminator(gt_images), labels_one) </span><br><span class="line">        fake_loss = loss_fn(discriminator(pred_images.detach()), labels_zero) </span><br><span class="line">        d_loss = (real_loss + fake_loss)</span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;step:<span class="subst">&#123;<span class="built_in">len</span>(dataloader)*epoch+i&#125;</span>, g_loss:<span class="subst">&#123;g_loss.item()&#125;</span>, d_loss:<span class="subst">&#123;d_loss.item()&#125;</span>&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">400</span> == <span class="number">0</span>:</span><br><span class="line">            image = pred_images[:<span class="number">16</span>].data</span><br><span class="line">            image = <span class="number">0.5</span> * (image + <span class="number">1</span>)</span><br><span class="line">            image = image.cpu().numpy()</span><br><span class="line">            plt.figure(figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">                plt.subplot(<span class="number">4</span>, <span class="number">4</span>, j+<span class="number">1</span>)</span><br><span class="line">                plt.imshow(image[j, <span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">                plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">            plt.show()</span><br><span class="line">     </span><br></pre></td></tr></table></figure>
<p>立杆见影：</p>
<table><tr>
    <td><img src="/2023/04/14/GAN2D/image_0.png"></td>
    <td><img src="/2023/04/14/GAN2D/image_937.png" alt="image_937"></td>
    <td><img src="/2023/04/14/GAN2D/image_2811.png" alt="image_2811"></td>
    <td><img src="/2023/04/14/GAN2D/image_4148.png" alt="image_4148"></td>
    <td><img src="/2023/04/14/GAN2D/image_5085.png" alt="image_5085"></td>
    <td><img src="/2023/04/14/GAN2D/image_6022.png" alt="image_6022"></td>
</tr></table>
<table><tr>
    <td><img src="/2023/04/14/GAN2D/image_7359.png"></td>
    <td><img src="/2023/04/14/GAN2D/image_8296.png" alt="image_8296"></td>
    <td><img src="/2023/04/14/GAN2D/image_9233.png"></td>
    <td><img src="/2023/04/14/GAN2D/image_10307.png" alt="image_10307"></td>
    <td><img src="/2023/04/14/GAN2D/image_15392.png" alt="image_15392"></td>
    <td><img src="/2023/04/14/GAN2D/image_16866.png"></td>
</tr></table>
<p>上述分别为是Epoch= 0，1000，3000，4000，5000，6000，7000，8000，9000，10000，15000，16000时的图像。非常nice。</p>
<h3 id="卷积对抗神经网络">卷积对抗神经网络</h3>
<h4 id="卷积对抗神经网络1">卷积对抗神经网络1</h4>
<p>有GPU的可以尝试一下，内存小的话，很快就会爆掉，这是代码，死慢死慢的！！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision.utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">z_dim = <span class="number">100</span>  </span><br><span class="line">lr = <span class="number">0.0003</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment">#张量转换</span></span><br><span class="line">img_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 MNIST </span></span><br><span class="line">mnist = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=img_transform, download=<span class="literal">True</span>)</span><br><span class="line">data_loader = DataLoader(mnist, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.AvgPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.AvgPool2d(<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(z_dim, <span class="number">256</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">256</span>),</span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">1024</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>))</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">64</span>, <span class="number">32</span>, <span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ConvTranspose2d(<span class="number">32</span>, <span class="number">1</span>, <span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Tanh())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义判别器和生成器</span></span><br><span class="line">D = Discriminator()</span><br><span class="line">G = Generator()</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">D.to(device)</span><br><span class="line">G.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">d_optimizer = optim.Adam(D.parameters(), lr=lr)</span><br><span class="line">g_optimizer = optim.Adam(G.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义真和假标签</span></span><br><span class="line">real_label = <span class="number">1</span></span><br><span class="line">fake_label = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于每个epoch</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 对于每个batch</span></span><br><span class="line">    <span class="keyword">for</span> i, (images, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader):</span><br><span class="line">        batch_size = images.size(<span class="number">0</span>)</span><br><span class="line">        images = images.view(batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练判别器</span></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 真实数据</span></span><br><span class="line">        real_outputs = D(images)</span><br><span class="line">        real_loss = criterion(real_outputs, torch.ones(batch_size, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 生成数据</span></span><br><span class="line">        z = torch.randn(batch_size, z_dim).to(device)</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        fake_outputs = D(fake_images.detach())</span><br><span class="line">        fake_loss = criterion(fake_outputs, torch.zeros(batch_size, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 计算总损失</span></span><br><span class="line">        d_loss = real_loss + fake_loss</span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练生成器</span></span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line">        z = torch.randn(batch_size, z_dim).to(device)</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        fake_outputs = D(fake_images)</span><br><span class="line">        g_loss = criterion(fake_outputs, torch.ones(batch_size, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印损失</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], d_loss: &#123;:.4f&#125;, g_loss: &#123;:.4f&#125;,&#x27;</span></span><br><span class="line">      <span class="string">&#x27;D(x): &#123;:.2f&#125;, D(G(z)): &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs, i+<span class="number">1</span>, <span class="built_in">len</span>(data_loader),d_loss.item(), g_loss.item(),real_score.mean().item(), fake_score.mean().item()))</span><br><span class="line">    <span class="comment"># 生成并打印图像</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    z = torch.randn(<span class="number">25</span>, latent_size, device=device)</span><br><span class="line">    fake_images = G(z).reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    img_grid = torchvision.utils.make_grid(fake_images, nrow=<span class="number">5</span>, normalize=<span class="literal">True</span>)</span><br><span class="line">    img_array = img_grid.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).cpu().numpy()</span><br><span class="line">    plt.imshow(img_array)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>我电脑有点垃，运行不到1个epoch，它就把我的电脑干掉了~~~不过，不到一个回合运行成这样，还是相当不错的。</p>
<p>卷积代码请参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41278720/article/details/80861284">1</a>，根据需求自行修改。</p>
<table><tr>
    	<td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_03-41-59.png" style="zoom:70%;"></td>
    	<td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-14-09.png" style="zoom:70%;"></td>
</tr><tr><table>
<p>右边是改的一个简化版本，两个都是第100个epoch，1000epoch的时候大概率快了2min，不过这个模型怎么改都非常慢。已经进化到甲骨文时代了。不过，1000次epoch要花大概8min，还是算了，pass，xxx</p>
<h4 id="卷积对抗神经网络2">卷积对抗神经网络2</h4>
<p>这个就快多了，也不用gpu，关键是你可以看到他长大，很解压！！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> BatchNormalization, LeakyReLU</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential, Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义生成器模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_generator</span>():</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Dense(<span class="number">7</span>*<span class="number">7</span>*<span class="number">256</span>, input_shape=(<span class="number">100</span>,)))</span><br><span class="line">    model.add(Reshape((<span class="number">7</span>, <span class="number">7</span>, <span class="number">256</span>)))</span><br><span class="line">    model.add(Conv2DTranspose(<span class="number">128</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">    model.add(BatchNormalization())</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.01</span>))</span><br><span class="line">    model.add(Conv2DTranspose(<span class="number">64</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">    model.add(BatchNormalization())</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.01</span>))</span><br><span class="line">    model.add(Conv2DTranspose(<span class="number">1</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=Adam(lr=<span class="number">0.0002</span>, beta_1=<span class="number">0.5</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义判别器模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_discriminator</span>():</span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Conv2D(<span class="number">64</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.01</span>))</span><br><span class="line">    model.add(Conv2D(<span class="number">128</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">    model.add(LeakyReLU(alpha=<span class="number">0.01</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=Adam(lr=<span class="number">0.0002</span>, beta_1=<span class="number">0.5</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义GAN网络</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_gan</span>(<span class="params">generator, discriminator</span>):</span><br><span class="line">    discriminator.trainable = <span class="literal">False</span></span><br><span class="line">    gan_input = Input(shape=(<span class="number">100</span>,))</span><br><span class="line">    x = generator(gan_input)</span><br><span class="line">    gan_output = discriminator(x)</span><br><span class="line">    gan = Model(inputs=gan_input, outputs=gan_output)</span><br><span class="line">    gan.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=Adam(lr=<span class="number">0.0002</span>, beta_1=<span class="number">0.5</span>))</span><br><span class="line">    <span class="keyword">return</span> gan</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练GAN网络</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_gan</span>(<span class="params">generator, discriminator, gan, epochs=<span class="number">100</span>, batch_size=<span class="number">128</span></span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># 训练判别器</span></span><br><span class="line">        noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, <span class="number">100</span>))</span><br><span class="line">        fake_images = generator.predict(noise)</span><br><span class="line">        real_images = train_images[np.random.randint(<span class="number">0</span>, train_images.shape[<span class="number">0</span>], batch_size)]</span><br><span class="line">        x = np.concatenate((real_images, fake_images))</span><br><span class="line">        y = np.zeros(<span class="number">2</span> * batch_size)</span><br><span class="line">        y[:batch_size] = <span class="number">0.9</span></span><br><span class="line">        discriminator_loss = discriminator.train_on_batch(x, y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练生成器</span></span><br><span class="line">        noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (batch_size, <span class="number">100</span>))</span><br><span class="line">        y = np.ones(batch_size)</span><br><span class="line">        generator_loss = gan.train_on_batch(noise, y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每10个epoch保存一次生成器的输出</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#x27;</span>, epoch, <span class="string">&#x27;Discriminator Loss:&#x27;</span>, discriminator_loss, <span class="string">&#x27;Generator Loss:&#x27;</span>, generator_loss)</span><br><span class="line">            save_images(generator, epoch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存生成器的输出</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">generator, epoch</span>):</span><br><span class="line">    noise = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">25</span>, <span class="number">100</span>))</span><br><span class="line">    fake_images = generator.predict(noise)</span><br><span class="line">    fake_images = <span class="number">0.5</span> * fake_images + <span class="number">0.5</span></span><br><span class="line">    fig, axs = plt.subplots(<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            axs[i,j].imshow(fake_images[cnt, :, :, <span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">            axs[i,j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">            cnt += <span class="number">1</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载MNIST数据集</span></span><br><span class="line">(train_images, _), (_, _) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图像归一化到-1到1之间</span></span><br><span class="line">train_images = (train_images.astype(<span class="string">&#x27;float32&#x27;</span>) - <span class="number">127.5</span>) / <span class="number">127.5</span></span><br><span class="line">train_images = np.expand_dims(train_images, axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建GAN网络并训练</span></span><br><span class="line">generator = build_generator()</span><br><span class="line">discriminator = build_discriminator()</span><br><span class="line">gan = build_gan(generator, discriminator)</span><br><span class="line"></span><br><span class="line">train_gan(generator, discriminator, gan, epochs=<span class="number">10000</span>, batch_size=<span class="number">128</span>)</span><br></pre></td></tr></table></figure>
<p>下面的美图和表格按位置分别对应，数字代表epoch</p>
<table>
<thead>
<tr>
<th style="text-align:center">0</th>
<th style="text-align:center">50</th>
<th style="text-align:center">100</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">200</td>
<td style="text-align:center">400</td>
<td style="text-align:center">600</td>
</tr>
<tr>
<td style="text-align:center">700</td>
<td style="text-align:center">900</td>
<td style="text-align:center">1000</td>
</tr>
</tbody>
</table>
<table><tr>
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-47-40.png" style="zoom:38%;"></td>
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-48-00.png" alt="Snipaste_2023-04-14_04-48-00" style="zoom:38%;"></td>
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-48-15.png" alt="Snipaste_2023-04-14_04-48-15" style="zoom:38%;"></td>
</tr><tr><table>
<table><tr>
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-48-34.png" alt="Snipaste_2023-04-14_04-48-34" style="zoom:38%;"></td>
	<td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-48-58.png" alt="Snipaste_2023-04-14_04-48-58" style="zoom:38%;"></td>
	<td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-49-19.png" alt="Snipaste_2023-04-14_04-49-19" style="zoom:38%;"></td>
</tr><tr><table>
<table><tr> 
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-49-48.png" alt="Snipaste_2023-04-14_04-49-48" style="zoom:38%;"></td>
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-50-50.png" alt="Snipaste_2023-04-14_04-50-50" style="zoom:38%;"></td>
    <td><img src="/2023/04/14/GAN2D/Snipaste_2023-04-14_04-57-08.png" alt="Snipaste_2023-04-14_04-57-08" style="zoom:38%;"></td>
</tr><tr><table>
<p>在Gan网络的加持下，1000次学习之后，这些字体基本可以认为是人写的了。当然，图片也是一样得原理，彩色图片采用。</p>
<hr>
<p>嗯嗯，差不多了，下次接着写</p>
<p>预告——使用gan网络生成3d模型，然后进入<strong>球棍模型</strong>预测</p>
</table></tr></table></table></tr></table></table></tr></table></table></tr></table></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://genewlan.github.io">ZhangLei</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://genewlan.github.io/2023/04/14/GAN2D/">http://genewlan.github.io/2023/04/14/GAN2D/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://genewlan.github.io" target="_blank">GeneWlan</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/GANS/">GANS</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/04/29/five-industrial-algorithm/" title="five industrial algorithm"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">five industrial algorithm</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/24/GUN1D/" title="分子指纹与其应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">分子指纹与其应用</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ZhangLei</div><div class="author-info__description">change or die!</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/genewlan/" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:xiaolobglee@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">GUNs的发迹史——刨根问底儿</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">GUNs有啥用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">GUN的实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8keras%E6%90%AD%E4%B8%80%E4%B8%AA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%A4%B1%E8%B4%A5%E6%A1%88%E4%BE%8B"><span class="toc-number">3.1.</span> <span class="toc-text">用keras搭一个神经网络的失败案例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%A2pytorch%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.2.</span> <span class="toc-text">换pytorch数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.2.1.</span> <span class="toc-text">非卷积对抗神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.2.2.</span> <span class="toc-text">卷积对抗神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C1"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">卷积对抗神经网络1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C2"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">卷积对抗神经网络2</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/30/Neural-Network-Frame/" title="Neural-Network-Frame">Neural-Network-Frame</a><time datetime="2023-09-30T10:55:16.000Z" title="发表于 2023-09-30 18:55:16">2023-09-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/30/bayes-net/" title="bayes-net">bayes-net</a><time datetime="2023-09-30T10:49:09.000Z" title="发表于 2023-09-30 18:49:09">2023-09-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/Practise/" title="LDA Modeling Practise">LDA Modeling Practise</a><time datetime="2023-08-31T06:45:25.000Z" title="发表于 2023-08-31 14:45:25">2023-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/31/%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3LDA%E4%B8%BB%E9%A2%98%E6%A8%A1/" title="通俗理解LDA主题模">通俗理解LDA主题模</a><time datetime="2023-08-31T06:09:26.000Z" title="发表于 2023-08-31 14:09:26">2023-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/07/31/outlier-detection/" title="outlier_detection">outlier_detection</a><time datetime="2023-07-31T14:40:34.000Z" title="发表于 2023-07-31 22:40:34">2023-07-31</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 By ZhangLei</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'J0s1l0MeDfMbgw4y4awgy2jX-MdYXbMMI',
      appKey: '3vZoaKxqWQYlKbXXdXuSxBsT',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div><!-- hexo injector body_end start --><div id="background-effect"></div><script src="https://cdn.jsdelivr.net/npm/three@0.121.1/build/three.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanta/dist/vanta.birds.min.js"></script><script>VANTA.BIRDS({"el":"#background-effect","mouseControls":true,"touchControls":true,"gyroControls":false,"minHeight":200,"minWidth":200,"scale":1,"scaleMobile":1})</script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacityDefault":1,"opacityOnHover":1},"log":false,"tagMode":false});</script></body></html>